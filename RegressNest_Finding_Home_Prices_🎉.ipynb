{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGIkohGOd8_V",
        "outputId": "d6dd6768-071e-4ddb-d322-fceef434bb10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of columns: 81\n",
            "Missing values in each column:\n",
            " Id                 0\n",
            "MSSubClass         0\n",
            "MSZoning           0\n",
            "LotFrontage      259\n",
            "LotArea            0\n",
            "                ... \n",
            "MoSold             0\n",
            "YrSold             0\n",
            "SaleType           0\n",
            "SaleCondition      0\n",
            "SalePrice          0\n",
            "Length: 81, dtype: int64\n",
            "Missing values after handling:\n",
            " Id               0\n",
            "MSSubClass       0\n",
            "MSZoning         0\n",
            "LotFrontage      0\n",
            "LotArea          0\n",
            "                ..\n",
            "MoSold           0\n",
            "YrSold           0\n",
            "SaleType         0\n",
            "SaleCondition    0\n",
            "SalePrice        0\n",
            "Length: 81, dtype: int64\n",
            "R² score for Ridge Regression: 0.8365697082847783\n",
            "R² score for Lasso Regression: -0.0008824918802494697\n",
            "R² score comparison:\n",
            "Ridge Regression: 0.8365697082847783\n",
            "Lasso Regression: -0.0008824918802494697\n",
            "Multiple Linear Regression: 0.75\n",
            "Optimal alpha for Ridge: 10.0\n",
            "Optimal alpha for Lasso: 0.1\n",
            "Optimized R² score for Ridge Regression: 0.8142332448284711\n",
            "Optimized R² score for Lasso Regression: 0.011807146042154382\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LassoCV\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "house_price = pd.read_csv('train.csv')\n",
        "house_price.to_csv('house_price.csv', index=False)\n",
        "\n",
        "# 1. Number of columns\n",
        "num_columns = house_price.shape[1]\n",
        "print(f\"Number of columns: {num_columns}\")\n",
        "\n",
        "# 2. Missing values\n",
        "missing_values = house_price.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_values)\n",
        "\n",
        "# Separate numerical and categorical columns\n",
        "numerical_cols = house_price.select_dtypes(include=['float64', 'int64']).columns\n",
        "categorical_cols = house_price.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Fill missing values for numerical columns with the mean\n",
        "house_price[numerical_cols] = house_price[numerical_cols].fillna(house_price[numerical_cols].mean())\n",
        "\n",
        "# Fill missing values for categorical columns with the mode (modified to avoid the warning)\n",
        "for col in categorical_cols:\n",
        "    house_price[col] = house_price[col].fillna(house_price[col].mode()[0])\n",
        "\n",
        "# Verify if all missing values have been handled\n",
        "missing_values_after = house_price.isnull().sum()\n",
        "print(\"Missing values after handling:\\n\", missing_values_after)\n",
        "\n",
        "# 3. Encoding Categorical Variables\n",
        "for col in categorical_cols:\n",
        "    if house_price[col].nunique() <= 10:  # Example threshold for choosing One-Hot encoding\n",
        "        house_price = pd.get_dummies(house_price, columns=[col], drop_first=True)\n",
        "    else:\n",
        "        le = LabelEncoder()\n",
        "        house_price[col] = le.fit_transform(house_price[col])\n",
        "\n",
        "# 4. Scaling Numerical Features\n",
        "scaler = MinMaxScaler()\n",
        "house_price[numerical_cols] = scaler.fit_transform(house_price[numerical_cols])\n",
        "\n",
        "# 5. Splitting the Dataset\n",
        "X = house_price.drop('SalePrice', axis=1)\n",
        "y = house_price['SalePrice']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Ridge Regression Model\n",
        "ridge_model = Ridge(alpha=10)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# 7. Evaluating Ridge Regression\n",
        "y_pred_ridge = ridge_model.predict(X_test)\n",
        "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
        "print(f\"R² score for Ridge Regression: {r2_ridge}\")\n",
        "\n",
        "# 8. Lasso Regression Model\n",
        "lasso_model = Lasso(alpha=10)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# 9. Evaluating Lasso Regression\n",
        "y_pred_lasso = lasso_model.predict(X_test)\n",
        "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
        "print(f\"R² score for Lasso Regression: {r2_lasso}\")\n",
        "\n",
        "# 10. R² Score Comparison (assuming MLR score is available)\n",
        "r2_mlr = 0.75  # From previous analysis\n",
        "print(f\"R² score comparison:\")\n",
        "print(f\"Ridge Regression: {r2_ridge}\")\n",
        "print(f\"Lasso Regression: {r2_lasso}\")\n",
        "print(f\"Multiple Linear Regression: {r2_mlr}\")\n",
        "\n",
        "# 11. Ridge and Lasso Regression with Cross-Validation for Optimal Alpha\n",
        "alphas = [0.1, 1, 10, 100]\n",
        "\n",
        "# RidgeCV for optimal alpha\n",
        "ridge_cv = RidgeCV(alphas=alphas)\n",
        "ridge_cv.fit(X_train, y_train)\n",
        "optimal_alpha_ridge = ridge_cv.alpha_\n",
        "\n",
        "# LassoCV for optimal alpha\n",
        "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "optimal_alpha_lasso = lasso_cv.alpha_\n",
        "\n",
        "# Print optimal alphas\n",
        "print(f\"Optimal alpha for Ridge: {optimal_alpha_ridge}\")\n",
        "print(f\"Optimal alpha for Lasso: {optimal_alpha_lasso}\")\n",
        "\n",
        "# 12. Outlier Removal using Z-Scores\n",
        "numerical_cols_train = X_train.select_dtypes(include=[np.number])\n",
        "z_scores = np.abs(stats.zscore(numerical_cols_train))\n",
        "outliers = (z_scores > 3).any(axis=1)\n",
        "\n",
        "X_train_cleaned = X_train[~outliers]\n",
        "y_train_cleaned = y_train[~outliers]\n",
        "\n",
        "# Retrain Ridge and Lasso with optimized data\n",
        "ridge_optimized = Ridge(alpha=optimal_alpha_ridge)\n",
        "ridge_optimized.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "lasso_optimized = Lasso(alpha=optimal_alpha_lasso)\n",
        "lasso_optimized.fit(X_train_cleaned, y_train_cleaned)\n",
        "\n",
        "# 13. Optimized Model Evaluation\n",
        "r2_ridge_optimized = r2_score(y_test, ridge_optimized.predict(X_test))\n",
        "r2_lasso_optimized = r2_score(y_test, lasso_optimized.predict(X_test))\n",
        "\n",
        "# Print the optimized R² scores\n",
        "print(f\"Optimized R² score for Ridge Regression: {r2_ridge_optimized}\")\n",
        "print(f\"Optimized R² score for Lasso Regression: {r2_lasso_optimized}\")\n"
      ]
    }
  ]
}